%!TEX root = alga.tex
\section{Graphs \`{a} la carte}\label{sec-a-la-carte}

In this section we define several useful \hs{Graph} instances, and
show that the algebra presented in the previous section~\S\ref{sec-algebra} is
not restricted only
to directed graphs, but can be extended to axiomatically represent undirected,
reflexive, transitively closed, and labelled graphs, their various
combinations, and even hypergraphs.

\begin{figure}[b]
\vspace{-3mm}
\begin{minted}{haskell}
import           Data.Set (Set, @\blk{singleton, union, elems, fromAscList}@)
import qualified Data.Set as Set (empty)
\end{minted}
\vspace{1mm}
\begin{minted}{haskell}
data Relation a = Relation { domain :: Set a, relation :: Set (a, a) } deriving (Eq, Show)
\end{minted}
\vspace{1mm}
\begin{minted}{haskell}
instance Ord a => Graph (Relation a) where
    type Vertex (Relation a) = a
    empty       = Relation Set.empty Set.empty
    vertex  x   = Relation (singleton x) Set.empty
    overlay x y = Relation (domain x `union` domain y) (relation x `union` relation y)
    connect x y = Relation (domain x `union` domain y) (relation x `union` relation y
        `union` fromAscList [ (a, b) | a <- elems (domain x), b <- elems (domain y) ])
\end{minted}
\vspace{-3mm}
\caption{Implementing the \hs{Graph} type class by a binary relation
and the core graph construction primitives
defined in~\S\ref{sub-constructing}\label{fig-relation}}
\vspace{-3mm}
\end{figure}

\subsection{Binary relation}\label{sub-relation}

We start by a direct encoding of the graph construction primitives defined
in~\S\ref{sub-constructing} into the \hs{Relation} data type isomorphic
to a pair of sets $(V,E)$, see Fig.~\ref{fig-relation}. As we have seen,
this implementation satisfies the axioms of the graph algebra. Furthermore, it
is a \emph{free graph} in the sense that it does not satisfy any other laws.
This follows from the fact that any algebraic graph expression $g$ can be
rewritten in the following \emph{canonical form}:
\[
g = \Big(\sum_{v\in V_g} v\Big) + \Big(\sum_{(u,v)\in E_g} \hspace{-1mm} u \rightarrow v\Big),
\]
\vspace{-1mm}
\noindent
where $V_g$ is the set of vertices that appear in $g$, and $(u,v)\in E_g$ if
vertices $u$ and $v$ appear in the left-hand and right-hand arguments of
the connect operation $\rightarrow$ at least once (and should thus be connected
by an edge). The canonical form of an
expression $g$ can be represented as \hs{Relation@$\,\,V_g\,E_g$@},
and any additional law on \hs{Relation} would violate the canonicity property.
The existence of the canonical form has been proved by~\citet{2014_algebra_mokhov}
for an extended version of the algebra. The proof fundamentally builds on the
decomposition axiom: one can apply it repeatedly to an expression, breaking up
connect sequences $x\rightarrow y\rightarrow z$ into pairs $x \rightarrow y$
until the decomposition can no longer be applied. We can then open the parentheses
using the distributivity and rearrange terms into the canonical expression
by the commutativity and idempotence of the overlay $+$ operation.

It is convenient to make \hs{Relation} an instance of the \hs{Num} type class
to use the standard $+$ and $*$ operators as shortcuts for \hs{overlay} and
\hs{connect}, respectively:

\begin{minted}{haskell}
instance (Ord a, Num a) => Num (Relation a) where
    fromInteger = vertex . fromInteger
    (+)         = overlay
    (*)         = connect
    signum      = const empty
    abs         = id
    negate      = id
\end{minted}

\noindent
Note that the \hs{Num} law \hs{@\blk{abs}@ x * signum x == x} is satisfied by the above
definition since $x \rightarrow \varepsilon = x$. In fact, any \hs{Graph} instance
can be made a law-abiding \hs{Num} instance if need be, using a definition similar to the above.

We can now play with graphs and binary relations using the interactive GHC:

\begin{minted}[frame=single]{haskell}
@\ghci@ 1 * (2 + 3) :: Relation Int
Relation {domain = fromList [1,2,3], relation = fromList [(1,2),(1,3)]}
@\ghci@ 1 * (2 + 3) + 2 * 3 == (clique [1..3] :: Relation Int)
True
@\ghci@ 1 * 2 == (2 * 1 :: Relation Int)
False
@\ghci \blk{:t}@ clique "abcd"
clique "abcd" :: (Graph g, Vertex g @\teq@ Char) => g
@\ghci @relation (clique "abcd")
fromList [('a','b'),('a','c'),('a','d'),('b','c'),('b','d'),('c','d')]
\end{minted}

\noindent
The last example highlights the fact that the \hs{Relation@\,\,\blk{a}@} instance allows vertices
of any type \hs{@\blk{a}@} that satisfies the~\hs{Ord@\,\,\blk{a}@} constraint.

\subsection{Deep embedding}\label{sub-embedding}

By embedding the core graph construction primitives into a basic algebraic data type
we obtain the following simple \hs{Graph} instance:

\begin{minted}{haskell}
data Expr a = Empty | Vertex a | Overlay (Expr a) (Expr a) | Connect (Expr a) (Expr a)
    deriving Show

instance Graph (Expr a) where
    type Vertex (Expr a) = a
    empty   = Empty
    vertex  = Vertex
    overlay = Overlay
    connect = Connect
\end{minted}

The instance definition provides a mapping from the \emph{shallow embedding}
of the core primitives, represented by the type class \hs{Graph}, into the
corresponding \emph{deep embedding}, represented by the data type \hs{Expr}.
It is known, e.g. see~\citet{2014_gibbons_folding}, that by \emph{folding} the data
type one can always obtain the inverse mapping:

\begin{minted}{haskell}
fold :: (Graph g, Vertex g @\teq@ a) => Expr a -> g
fold Empty         = empty
fold (Vertex  x  ) = vertex x
fold (Overlay x y) = overlay (fold x) (fold y)
fold (Connect x y) = connect (fold x) (fold y)
\end{minted}

We cannot use the derived \hs{Eq} instance of the \hs{Expr} data type, because it
would clearly violate the axioms of the algebra, e.g. \hs{Overlay@\,\,@Empty@\,\,@Empty} is
structurally different from \hs{Empty}, but they must be equal according to the axioms.
However, we can implement a custom law-abiding \hs{Eq}
instance by \emph{reinterpreting} the graph expression \hs{Expr}
as a \hs{Relation}, thereby gaining access to the canonical graph representation:

\begin{minted}{haskell}
instance Ord a => Eq (Expr a) where
    x == y = fold x == (fold y :: Relation a)
\end{minted}

An interesting feature of the \hs{Expr} instance is that it allows to represent
densely connected graphs more compactly. For example, \hs{clique [1..n] :: Expr Int}
has a linear-size representation in memory, while \hs{clique [1..n] :: Relation Int}
stores each edge separately and therefore uses $O(n^2)$ memory. Exploiting the
compact graph representation for deriving algorithms that are asymptotically faster
on dense graphs, compared to conventional algorithms operating on `uncompressed'
graph representations isomorphic to $(V,E)$, is outside the scope of this paper,
but is an interesting direction of future research.

\begin{figure}[b]
\vspace{-2mm}
\begin{minted}{haskell}
import           Data.Map.Strict (Map, keysSet, fromSet)
import qualified Data.Map.Strict as Map
import           Data.Set (Set)
import qualified Data.Set as Set
\end{minted}
\vspace{1mm}
\begin{minted}{haskell}
newtype AdjacencyMap a = AM { adjacencyMap :: Map a@\,\,@(Set a) }@\,\,@deriving@\,\,@(Arbitrary,@\,\,@Eq,@\,\,@Show)
\end{minted}
\vspace{1mm}
\begin{minted}{haskell}
instance Ord a => Graph (AdjacencyMap a) where
    type Vertex (AdjacencyMap a) = a
    empty       = AM $ Map.empty
    vertex  x   = AM $ Map.singleton x Set.empty
    overlay x y = AM $ Map.unionWith Set.union (adjacencyMap x) (adjacencyMap y)
    connect x y = AM $ Map.unionsWith Set.union [ adjacencyMap x, adjacencyMap y,
        fromSet (const . keysSet $ adjacencyMap y) (keysSet $ adjacencyMap x) ]
\end{minted}
\vspace{-3mm}
\caption{Implementing the \hs{Graph} type class by adjacency map\label{fig-adjacency-map}}
\vspace{-1mm}
\end{figure}

\subsection{Adjacency map and topological sort}\label{sub-adjacency-map}

In this subsection we show how to reuse existing graph libraries, such as
\textsf{containers} and \textsf{fgl}, by wrapping them into the algebraic
graph API. More specifically, we show how to reuse the efficient implementation of
the \emph{topological sort} algorithm developed by~\citet{1995_king_graphs}.

The interface of the \textsf{containers} library uses the \emph{adjacency list}
representation of graphs and we therefore define a new \hs{Graph} instance that
provides the closest match, see Fig.~\ref{fig-adjacency-map}. In our experiments
this instance is often faster than \hs{Relation} because of more efficient
sharing of common subgraphs in memory, see~\S\ref{sub-benchmarks}.

The \hs{AdjacencyMap} instance is parametric and in order to use the
functions provided by \textsf{containers}, we need to map the graph vertices
into contiguous subsets of integers \hs{Int}. This can be done by the function
\hs{graphFromEdges} defined in \textsf{containers} that requires an adjacency list as
the input. We can obtain the adjacency list from \hs{AdjacencyMap} as follows:

\begin{minted}{haskell}
adjacencyList :: AdjacencyMap a -> [(a, [a])]
adjacencyList = @\std{map}@ (@\std{fmap}@ Set.toAscList) . Map.toAscList . adjacencyMap
\end{minted}
Both \textsf{containers} and \textsf{fgl} also provide graph constructors from the
\emph{edge list} graph representation, which can be readily obtained from
\hs{adjacencyList}:

\begin{minted}{haskell}
edgeList :: AdjacencyMap a -> [(a, a)]
edgeList = concatMap (\(x, ys) -> @\std{map}@ (x,) ys) . adjacencyList
\end{minted}

\noindent
Let's test that \hs{AdjacencyMap} is a valid \hs{Graph} instance and
showcase \hs{adjacencyList} and \hs{edgeList}:

\begin{minted}[frame=single]{haskell}
@\ghci @quickCheck (axioms :: GraphTestsuite (AdjacencyMap Int))
@\blk{+++ OK, passed 100 tests.}@

@\ghci @adjacencyList $ clique [1..4]
[(1,[2,3,4]),(2,[3,4]),(3,[4]),(4,[@@])]

@\ghci @edgeList $ edges [('a','b'),('b','c'),('a','b')]
[('a','b'),('b','c')]
\end{minted}

We can now build safe bridges to \textsf{containers} and \textsf{fgl}. Consider
the following wrapper\footnote{We use \textsf{GeneralizedNewtypeDeriving} GHC
extension to derive \hs{Arbitrary}, \hs{Graph} and \hs{Num} instances. Note that
the current version of GHC does not support the extension for classes
with associated types, such as \hs{Graph}, but the feature has already been
implemented and will be available in the next GHC release. Until then
one needs to write the trivial \hs{Graph} instance manually.}
around \hs{AdjacencyMap}:

\begin{minted}{haskell}
newtype TopSort a = TS (AdjacencyMap a) deriving (Arbitrary, Graph, Num, Show)
\end{minted}
\vspace{1mm}
\begin{minted}{haskell}
instance Ord a => Eq (TopSort a) where
    x == y = topSort x == topSort y
\end{minted}
\vspace{1mm}
\begin{minted}{haskell}
topSort :: Ord a => TopSort a -> Maybe [a]
topSort = ... -- call Data.Graph.topSort via Data.Graph.graphFromEdges
\end{minted}

\noindent
The \hs{TopSort} instance differs from \hs{AdjacencyMap} only in one aspect: it uses
a custom equality test, which satisfies more laws than required by the \hs{Graph}
instance. Indeed, there are many pairs of different graphs, whose topological sorts
coincide, e.g. \hs{topSort (1 + 2)} = \hs{topSort (1 * 2)} = \hs{Just [1,2]}.

We do not show the implementation of the \hs{topSort} function here, as it is not
particularly interesting and involves low-level plumbing, however we would like to
emphasise that the resulting interface is fully parametric and safe. Note the
return type of \hs{topSort}: the function returns \hs{Nothing}
if a topological sort does not exist because the graph is cyclic; otherwise it
returns a list of vertices in the topological order, as demonstrated below:

\begin{minted}[frame=single]{haskell}
@\ghci @quickCheck (axioms :: GraphTestsuite (TopSort Int))
@\blk{+++ OK, passed 100 tests.}@

@\ghci @topSort $ 1 * 2 + 3 * 1
Just [3,1,2]

@\ghci @topSort $ 1 * 2 + 2 * 1
Nothing
\end{minted}

\subsection{Undirected graphs}\label{sub-undirected}

As hinted in \S\ref{sub-laws}, to switch from directed to undirected graphs it
is sufficient to add the axiom of commutativity for the connect operator. For
undirected graphs it makes sense to denote the connect operation by $\leftrightarrow$ or
\textemdash, hence:

\begin{itemize}
    \item $\leftrightarrow$ is commutative: $x \leftrightarrow y = y \leftrightarrow x$.
\end{itemize}

Curiously, with the introduction of this axiom, the associativity of $\leftrightarrow$
follows from the left-associated version of the decomposition axiom and the
commutativity of $+$:
\[
\begin{array}{rcll}
(x \leftrightarrow y) \leftrightarrow z & = & x \leftrightarrow y + x \leftrightarrow z + y \leftrightarrow z & \text{(left decomposition)}\\
 & = & y \leftrightarrow z + y \leftrightarrow x + z \leftrightarrow x & \text{(commutativity of $+$ and $\leftrightarrow$)}\\
 & = &  (y \leftrightarrow z) \leftrightarrow x & \text{(left decomposition)}\\
 & = &   x \leftrightarrow (y \leftrightarrow z) & \text{(commutativity of $\leftrightarrow$)}\\
\end{array}
\]

Therefore, \emph{the minimal set of axioms of undirected graphs} comprises only 6 axioms:

\begin{itemize}
    \item $+$ is commutative and associative: $x + y = y + x$ and
    $x + (y + z) = (x + y) + z$.
    \item $\leftrightarrow$ is commutative $x \leftrightarrow y = y \leftrightarrow x$ and
    has $\varepsilon$ is the identity: $x \leftrightarrow \varepsilon = x$.
    \item Distributivity:
    $x \leftrightarrow (y + z) = x \leftrightarrow y + x \leftrightarrow z$.
    \item Left decomposition: $(x \leftrightarrow y) \leftrightarrow z =
    x \leftrightarrow y + x \leftrightarrow z + y \leftrightarrow z$.
\end{itemize}

Commutativity of the connect operator forces graph expressions that differ only
in the direction of edges into the same equivalence class. One can implement
this by the \emph{symmetric closure} of the underlying relation:

\begin{minted}{haskell}
newtype Undirected a = U (Relation a) deriving (Arbitrary, Graph, Num, Show)

instance Ord a => Eq (Undirected a) where
    U x == U y = symmetricClosure x == symmetricClosure y

symmetricClosure :: Ord a => Relation a -> Relation a
symmetricClosure = ... -- direct edges canonically or make them bidirectional
\end{minted}

Note that algebraic expressions of undirected graphs have the canonical form where all
edges are directed in a canonical order, e.g. according to some total order on vertices.

Let's test that the custom equality works as desired:
\begin{minted}[frame=single]{haskell}
@\ghci @quickCheck (axioms :: GraphTestsuite (Undirected Int))
+++ OK, passed 100 tests.

@\ghci @quickCheck $ \x y -> x * y == (y * x :: Undirected Int)
+++ OK, passed 100 tests.

@\ghci @clique "abcd" == (clique "dcba" :: Relation Char)
False

@\ghci @clique "abcd" == (clique "dcba" :: Undirected Char)
True
\end{minted}

As you can see, the polymorphic graph construction functions, such as \hs{clique},
can be safely used when working with undirected graphs. We can define a subclass
\hs{class Graph g => UndirectedGraph g} and use the \hs{UndirectedGraph g}
constraint for functions that rely on the commutativity of the \hs{connect} method.

\subsection{Reflexive and irreflexive graphs}

A graph is \emph{reflexive} if every vertex is connected to itself, i.e. has a self-loop.
An example of a reflexive graph is the graph corresponding to the partial
order relation $\subseteq$ on graphs: indeed, $x \subseteq x$ holds for all $x$. To
represent reflexive graphs algebraically we can introduce the following axiom:

\begin{itemize}
    \item $v = v \rightarrow v$, where $v\in \mathbb{V}$ is a vertex.
\end{itemize}

\noindent
The axiom corresponds to an additional \hs{Graph} type class law:
\hs{vertex x} = \hs{connect (}\hs{vertex x) (}\hs{vertex x)}.

One way to look at the axiom is that it enforces that each vertex has a self-loop. However,
there is another equally valid perspective, which corresponds to the reverse application
of the equality, wherein the axiom states that there are no self-loops! This may seem like an
internal contradiction of the theory, but in fact this simply indicates the isomorphism
between reflexive and \emph{irreflexive} graphs: you can always
turn a reflexive graph into the corresponding irreflexive one by deleting the self-loops,
and vice versa.

One can implement the reflexive and/or irreflexive \hs{Graph} instance very similarly to
the \hs{Undirected} implementation presented in~\S\ref{sub-undirected}: simply wrap
\hs{Relation} into a \hs{newtype} and give it a custom \hs{Eq} instance based on the
\hs{reflexiveClosure}.

We can define
\hs{class Graph g => ReflexiveGraph g} and \hs{class Graph g => IrreflexiveGraph g}
to increase the type safety of functions that rely on the additional axiom. It seems
strange to have two different type classes with exactly the same methods and laws, but
it may be useful to distinguish their semantics.

\subsection{Transitively closed graphs}

In many applications graphs satisfy the \emph{transitivity} property: if a vertex $x$ is
connected to $y$, and $y$ is connected to $z$, then the edge between $x$ and $z$ can be
added or removed without changing the semantics of the graph. A common example is
\emph{dependency graphs} or \emph{partial orders} --- the semantics of such graphs is
typically their \emph{transitive closure}.
To describe this class of graphs algebraically we add the following \emph{closure} axiom:

\begin{itemize}
    \item Closure: $y \neq \varepsilon \Rightarrow x \rightarrow y + y \rightarrow z +
    x \rightarrow z = x \rightarrow y + y \rightarrow z$.
\end{itemize}

By using the axiom one can rewrite a graph expression into its transitive closure or,
alternatively, into its \emph{transitive reduction}, hence all graphs that differ only in the
existence of some transitive edges are forced into the same equivalence class. Note that the
precondition $y \neq \varepsilon$ is necessary as otherwise $+$ and $\rightarrow$ can no
longer be distinguished:
\[
x \rightarrow z = x \rightarrow \varepsilon \rightarrow z = x \rightarrow \varepsilon
 + \varepsilon \rightarrow z + x \rightarrow z = x \rightarrow \varepsilon
 + \varepsilon \rightarrow z = x + z.
\]

It is interesting to note that $+$ and $\rightarrow$ have a simple meaning for transitively
closed graphs: they correspond to the \emph{parallel} and \emph{sequential composition},
respectively. This allows to algebraically describe concurrent systems, which was one
of the original motivations behind the research on algebraic graphs.

We can implement a \hs{Graph} instance for transitively closed graphs by wrapping
\hs{Relation} in a \hs{newtype} with a custom equality function, which given two
graphs compares the transitive closures of the underlying relations.

The above implementation permits cycles in graphs, therefore the resulting equivalence
classes correspond to \emph{preorders}. For example, $(1 + 2 + 3) \rightarrow (2 + 3 + 4)$
is a preorder with vertices 2 and 3 forming a \emph{strongly-connected component}. By
finding all strongly-connected components in the graph (e.g. by using the function \hs{scc}
from the \textsf{containers} library) we can derive the following \emph{graph condensation}:
$\{1\} \rightarrow \{2, 3\} \rightarrow \{4\}$. One way to interpret this preorder as a
dependency graph is that tasks 2 and 3 are executed as a step,
simultaneously, and that they both depend on task 1, and are required for task 4.

A subclass \hs{class Graph g => TransitiveGraph g} can be defined to distinguish
algebraic graphs with the closure axiom from others.

\subsection{Hypergraphs}

As described in~\S\ref{sub-relation}, the decomposition axiom collapses an algebraic
graph expression into a collection of vertices and pairs of vertices, i.e. graphs. By replacing
the decomposition axiom with \emph{3-decomposition}, we obtain \emph{hypergraphs} comprising
vertices, edges and \emph{3-edges} (triples of vertices):

\begin{itemize}
    \item 3-decomposition: $w \rightarrow x \rightarrow y \rightarrow z =
    w \rightarrow x \rightarrow y + w \rightarrow x \rightarrow z +
    w \rightarrow y \rightarrow z + x \rightarrow y \rightarrow z$.
\end{itemize}

To better understand the difference between the (2-)decomposition and 3-decomposition
axioms, let's substitute~$\varepsilon$ for $w$ in the 3-decomposition and simplify:
\[
x \rightarrow y \rightarrow z = x \rightarrow y + x \rightarrow z + y \rightarrow z
+ x \rightarrow y \rightarrow z.
\]
Looks familiar? This is almost the 2-decomposition axiom! Yet there is no way to get rid
of the term $x \rightarrow y \rightarrow z$ on the right-hand side: indeed, a triple is
unbreakable
in this algebra, and one can only extract the pairs (edges) that are embedded in it.
In fact, we can take this further and rewrite the above expression to also expose the
embedded vertices:
\[
x \rightarrow y \rightarrow z = x + y + z + x \rightarrow y + x \rightarrow z
+ y \rightarrow z + x \rightarrow y \rightarrow z.
\]
Note that with 2-decomposition we can achieve something similar via the absorption theorem:
\[
x \rightarrow y = x + y + x \rightarrow y.
\]
This can be taken further by defining 4-decomposition and so forth, creating a hierarchy
of algebraic structures.

Since every graph is also a hypergraph, we can define a superclass
\hs{class HyperGraph g => Graph g}, moving all \hs{Graph} methods to the superclass, and
leaving only the decomposition axiom in \hs{Graph}, as the law that distinguishes it from
\hs{HyperGraph}.

\subsection{Summary}

In this section we have defined a family of graph instances and their classes that are all
build on the same algebraic core. The additional axioms that characterise these classes
can be mixed in various combinations. For example, the algebra of undirected, reflexive
and transitively closed graphs describes the laws of equivalence relations.

In the next section we present a library of basic graph transformation algorithms that
can be reused by all instances discussed in this section.
